{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2021-10-01T09:43:22.201983Z",
     "iopub.status.busy": "2021-10-01T09:43:22.201689Z",
     "iopub.status.idle": "2021-10-01T09:43:22.217227Z",
     "shell.execute_reply": "2021-10-01T09:43:22.216303Z",
     "shell.execute_reply.started": "2021-10-01T09:43:22.20195Z"
    }
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-01T09:43:22.220184Z",
     "iopub.status.busy": "2021-10-01T09:43:22.219966Z",
     "iopub.status.idle": "2021-10-01T09:43:23.94739Z",
     "shell.execute_reply": "2021-10-01T09:43:23.946597Z",
     "shell.execute_reply.started": "2021-10-01T09:43:22.220143Z"
    }
   },
   "outputs": [],
   "source": [
    "# data_raw = pd.read_csv('/kaggle/input/testtraintextmultilabel/train.csv')\n",
    "data_raw = pd.read_csv('.//data//train.csv')\n",
    "data_raw = data_raw[data_raw.iloc[:,2:8].sum(axis=1)>0]\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-01T09:43:23.950955Z",
     "iopub.status.busy": "2021-10-01T09:43:23.950536Z",
     "iopub.status.idle": "2021-10-01T09:43:23.978541Z",
     "shell.execute_reply": "2021-10-01T09:43:23.97772Z",
     "shell.execute_reply.started": "2021-10-01T09:43:23.950912Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows in data = 16225\n",
      "Number of columns in data = 8\n",
      "\n",
      "\n",
      "**Sample data:**\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0002bcb3da6cb337</td>\n",
       "      <td>COCKSUCKER BEFORE YOU PISS AROUND ON MY WORK</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0005c987bdfc9d4b</td>\n",
       "      <td>Hey... what is it..\\n@ | talk .\\nWhat is it......</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0007e25b2121310b</td>\n",
       "      <td>Bye! \\n\\nDon't look, come or think of comming ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>001810bf8c45bf5f</td>\n",
       "      <td>You are gay or antisemmitian? \\n\\nArchangel WH...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>00190820581d90ce</td>\n",
       "      <td>FUCK YOUR FILTHY MOTHER IN THE ASS, DRY!</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  id                                       comment_text  \\\n",
       "6   0002bcb3da6cb337       COCKSUCKER BEFORE YOU PISS AROUND ON MY WORK   \n",
       "12  0005c987bdfc9d4b  Hey... what is it..\\n@ | talk .\\nWhat is it......   \n",
       "16  0007e25b2121310b  Bye! \\n\\nDon't look, come or think of comming ...   \n",
       "42  001810bf8c45bf5f  You are gay or antisemmitian? \\n\\nArchangel WH...   \n",
       "43  00190820581d90ce           FUCK YOUR FILTHY MOTHER IN THE ASS, DRY!   \n",
       "\n",
       "    toxic  severe_toxic  obscene  threat  insult  identity_hate  \n",
       "6       1             1        1       0       1              0  \n",
       "12      1             0        0       0       0              0  \n",
       "16      1             0        0       0       0              0  \n",
       "42      1             0        1       0       1              1  \n",
       "43      1             0        1       0       1              0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Number of rows in data =\",data_raw.shape[0])\n",
    "print(\"Number of columns in data =\",data_raw.shape[1])\n",
    "print(\"\\n\")\n",
    "print(\"**Sample data:**\")\n",
    "data_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-01T09:43:23.980353Z",
     "iopub.status.busy": "2021-10-01T09:43:23.979969Z",
     "iopub.status.idle": "2021-10-01T09:43:23.987355Z",
     "shell.execute_reply": "2021-10-01T09:43:23.986473Z",
     "shell.execute_reply.started": "2021-10-01T09:43:23.980315Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 8)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_raw = data_raw.iloc[:2000, :]\n",
    "data_raw.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-01T09:43:23.990814Z",
     "iopub.status.busy": "2021-10-01T09:43:23.990348Z",
     "iopub.status.idle": "2021-10-01T09:43:25.398238Z",
     "shell.execute_reply": "2021-10-01T09:43:25.397438Z",
     "shell.execute_reply.started": "2021-10-01T09:43:23.990781Z"
    }
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "import re\n",
    "import sys\n",
    "import warnings\n",
    "data = data_raw\n",
    "if not sys.warnoptions:\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "def cleanHtml(sentence):\n",
    "    cleanr = re.compile('<.*?>')\n",
    "    cleantext = re.sub(cleanr, ' ', str(sentence))\n",
    "    return cleantext\n",
    "def cleanPunc(sentence): #function to clean the word of any punctuation or special characters\n",
    "    cleaned = re.sub(r'[?|!|\\'|\"|#]',r'',sentence)\n",
    "    cleaned = re.sub(r'[.|,|)|(|\\|/]',r' ',cleaned)\n",
    "    cleaned = cleaned.strip()\n",
    "    cleaned = cleaned.replace(\"\\n\",\" \")\n",
    "    return cleaned\n",
    "def keepAlpha(sentence):\n",
    "    alpha_sent = \"\"\n",
    "    for word in sentence.split():\n",
    "        alpha_word = re.sub('[^a-z A-Z]+', ' ', word)\n",
    "        alpha_sent += alpha_word\n",
    "        alpha_sent += \" \"\n",
    "    alpha_sent = alpha_sent.strip()\n",
    "    return alpha_sent\n",
    "data['comment_text'] = data['comment_text'].str.lower()\n",
    "data['comment_text'] = data['comment_text'].apply(cleanHtml)\n",
    "data['comment_text'] = data['comment_text'].apply(cleanPunc)\n",
    "data['comment_text'] = data['comment_text'].apply(keepAlpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-01T09:43:25.401846Z",
     "iopub.status.busy": "2021-10-01T09:43:25.401562Z",
     "iopub.status.idle": "2021-10-01T09:43:26.809817Z",
     "shell.execute_reply": "2021-10-01T09:43:26.809053Z",
     "shell.execute_reply.started": "2021-10-01T09:43:25.401818Z"
    }
   },
   "outputs": [],
   "source": [
    "stemmer = SnowballStemmer(\"english\")\n",
    "def stemming(sentence):\n",
    "    stemSentence = \"\"\n",
    "    for word in sentence.split():\n",
    "        stem = stemmer.stem(word)\n",
    "        stemSentence += stem\n",
    "        stemSentence += \" \"\n",
    "    stemSentence = stemSentence.strip()\n",
    "    return stemSentence\n",
    "data['comment_text'] = data['comment_text'].apply(stemming)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-01T09:43:26.811529Z",
     "iopub.status.busy": "2021-10-01T09:43:26.811246Z",
     "iopub.status.idle": "2021-10-01T09:43:26.823876Z",
     "shell.execute_reply": "2021-10-01T09:43:26.823154Z",
     "shell.execute_reply.started": "2021-10-01T09:43:26.811493Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0002bcb3da6cb337</td>\n",
       "      <td>cocksuck befor you piss around on my work</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0005c987bdfc9d4b</td>\n",
       "      <td>hey what is it talk what is it an exclus group...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0007e25b2121310b</td>\n",
       "      <td>bye dont look come or think of com back tosser</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>001810bf8c45bf5f</td>\n",
       "      <td>you are gay or antisemmitian archangel white t...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>00190820581d90ce</td>\n",
       "      <td>fuck your filthi mother in the ass dri</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  id                                       comment_text  \\\n",
       "6   0002bcb3da6cb337          cocksuck befor you piss around on my work   \n",
       "12  0005c987bdfc9d4b  hey what is it talk what is it an exclus group...   \n",
       "16  0007e25b2121310b     bye dont look come or think of com back tosser   \n",
       "42  001810bf8c45bf5f  you are gay or antisemmitian archangel white t...   \n",
       "43  00190820581d90ce             fuck your filthi mother in the ass dri   \n",
       "\n",
       "    toxic  severe_toxic  obscene  threat  insult  identity_hate  \n",
       "6       1             1        1       0       1              0  \n",
       "12      1             0        0       0       0              0  \n",
       "16      1             0        0       0       0              0  \n",
       "42      1             0        1       0       1              1  \n",
       "43      1             0        1       0       1              0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### set TF-IDF "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-01T09:43:26.82566Z",
     "iopub.status.busy": "2021-10-01T09:43:26.825261Z",
     "iopub.status.idle": "2021-10-01T09:43:26.832895Z",
     "shell.execute_reply": "2021-10-01T09:43:26.832217Z",
     "shell.execute_reply.started": "2021-10-01T09:43:26.825624Z"
    }
   },
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import train_test_split\n",
    "# train, test = train_test_split(data, random_state=42, test_size=0.30, shuffle=True)\n",
    "# from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# vectorizer = TfidfVectorizer(strip_accents='unicode', analyzer='word', ngram_range=(2,3), norm='l2')\n",
    "# vectorizer.fit(train.comment_text)\n",
    "# vectorizer.fit(test.comment_text)\n",
    "# x_train = vectorizer.transform(train.comment_text)\n",
    "# y_train = train.drop(labels = ['id','comment_text'], axis=1)\n",
    "# x_test = vectorizer.transform(test.comment_text)\n",
    "# y_test = test.drop(labels = ['id','comment_text'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-01T09:43:26.834625Z",
     "iopub.status.busy": "2021-10-01T09:43:26.834305Z",
     "iopub.status.idle": "2021-10-01T09:43:26.844569Z",
     "shell.execute_reply": "2021-10-01T09:43:26.843835Z",
     "shell.execute_reply.started": "2021-10-01T09:43:26.834592Z"
    }
   },
   "outputs": [],
   "source": [
    "# from sklearn.linear_model import LogisticRegression\n",
    "# from sklearn.pipeline import Pipeline\n",
    "# from sklearn.metrics import accuracy_score\n",
    "# from sklearn.multiclass import OneVsRestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-01T09:43:26.846467Z",
     "iopub.status.busy": "2021-10-01T09:43:26.846198Z",
     "iopub.status.idle": "2021-10-01T09:43:26.853077Z",
     "shell.execute_reply": "2021-10-01T09:43:26.852229Z",
     "shell.execute_reply.started": "2021-10-01T09:43:26.846436Z"
    }
   },
   "outputs": [],
   "source": [
    "# # Using pipeline for applying logistic regression and one vs rest classifier\n",
    "# LogReg_pipeline = Pipeline([\n",
    "#                 ('reg_clf', OneVsRestClassifier(LogisticRegression(solver='sag'), n_jobs=-1)),])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-01T09:43:26.85707Z",
     "iopub.status.busy": "2021-10-01T09:43:26.856764Z",
     "iopub.status.idle": "2021-10-01T09:43:26.862787Z",
     "shell.execute_reply": "2021-10-01T09:43:26.861886Z",
     "shell.execute_reply.started": "2021-10-01T09:43:26.857042Z"
    }
   },
   "outputs": [],
   "source": [
    "# categories = data.columns[2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-01T09:43:26.864508Z",
     "iopub.status.busy": "2021-10-01T09:43:26.864052Z",
     "iopub.status.idle": "2021-10-01T09:43:26.871436Z",
     "shell.execute_reply": "2021-10-01T09:43:26.870773Z",
     "shell.execute_reply.started": "2021-10-01T09:43:26.864474Z"
    }
   },
   "outputs": [],
   "source": [
    "# for category in categories:\n",
    "#     print('**Processing {} comments...**'.format(category))\n",
    "    \n",
    "#     # Training logistic regression model on train data\n",
    "#     LogReg_pipeline.fit(x_train, train[category])\n",
    "    \n",
    "#     # calculating test accuracy\n",
    "#     prediction = LogReg_pipeline.predict(x_test)\n",
    "#     print('Test accuracy is {}'.format(accuracy_score(test[category], prediction)))\n",
    "#     print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-01T09:43:26.872992Z",
     "iopub.status.busy": "2021-10-01T09:43:26.872607Z",
     "iopub.status.idle": "2021-10-01T09:43:26.880321Z",
     "shell.execute_reply": "2021-10-01T09:43:26.879582Z",
     "shell.execute_reply.started": "2021-10-01T09:43:26.872958Z"
    }
   },
   "outputs": [],
   "source": [
    "######################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! conda install -c conda-forge pytorch-lightning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-01T09:43:26.883453Z",
     "iopub.status.busy": "2021-10-01T09:43:26.883252Z",
     "iopub.status.idle": "2021-10-01T09:43:37.18262Z",
     "shell.execute_reply": "2021-10-01T09:43:37.181891Z",
     "shell.execute_reply.started": "2021-10-01T09:43:26.883429Z"
    }
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pytorch_lightning'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-3d6f7bb89cd8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mBertTokenizerFast\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mBertTokenizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mBertModel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mAdamW\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mget_linear_schedule_with_warmup\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mpytorch_lightning\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpl\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mpytorch_lightning\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunctional\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mauroc\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mpytorch_lightning\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcallbacks\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mModelCheckpoint\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mEarlyStopping\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pytorch_lightning'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import BertTokenizerFast as BertTokenizer, BertModel, AdamW, get_linear_schedule_with_warmup\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.metrics.functional import accuracy, f1, auroc\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, multilabel_confusion_matrix\n",
    "import seaborn as sns\n",
    "from pylab import rcParams\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rc\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format='retina'\n",
    "RANDOM_SEED = 42\n",
    "sns.set(style='whitegrid', palette='muted', font_scale=1.2)\n",
    "HAPPY_COLORS_PALETTE = [\"#01BEFE\", \"#FFDD00\", \"#FF7D00\", \"#FF006D\", \"#ADFF02\", \"#8F00FF\"]\n",
    "sns.set_palette(sns.color_palette(HAPPY_COLORS_PALETTE))\n",
    "rcParams['figure.figsize'] = 12, 8\n",
    "pl.seed_everything(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-01T09:43:37.184691Z",
     "iopub.status.busy": "2021-10-01T09:43:37.184229Z",
     "iopub.status.idle": "2021-10-01T09:43:37.190408Z",
     "shell.execute_reply": "2021-10-01T09:43:37.189599Z",
     "shell.execute_reply.started": "2021-10-01T09:43:37.18465Z"
    }
   },
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-01T09:43:37.192154Z",
     "iopub.status.busy": "2021-10-01T09:43:37.191893Z",
     "iopub.status.idle": "2021-10-01T09:43:37.200892Z",
     "shell.execute_reply": "2021-10-01T09:43:37.200214Z",
     "shell.execute_reply.started": "2021-10-01T09:43:37.192122Z"
    }
   },
   "outputs": [],
   "source": [
    "df = data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-01T09:43:37.202388Z",
     "iopub.status.busy": "2021-10-01T09:43:37.202026Z",
     "iopub.status.idle": "2021-10-01T09:43:37.226079Z",
     "shell.execute_reply": "2021-10-01T09:43:37.22544Z",
     "shell.execute_reply.started": "2021-10-01T09:43:37.202355Z"
    }
   },
   "outputs": [],
   "source": [
    "df[df.iloc[:,2:8].sum(axis=1) > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-01T09:43:37.227583Z",
     "iopub.status.busy": "2021-10-01T09:43:37.22727Z",
     "iopub.status.idle": "2021-10-01T09:43:37.233291Z",
     "shell.execute_reply": "2021-10-01T09:43:37.232495Z",
     "shell.execute_reply.started": "2021-10-01T09:43:37.227548Z"
    }
   },
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-01T09:43:37.235352Z",
     "iopub.status.busy": "2021-10-01T09:43:37.234525Z",
     "iopub.status.idle": "2021-10-01T09:43:37.245756Z",
     "shell.execute_reply": "2021-10-01T09:43:37.244952Z",
     "shell.execute_reply.started": "2021-10-01T09:43:37.235318Z"
    }
   },
   "outputs": [],
   "source": [
    "train_df, val_df = train_test_split(df, test_size=0.2)\n",
    "train_df.shape, val_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-01T09:43:37.247624Z",
     "iopub.status.busy": "2021-10-01T09:43:37.247042Z",
     "iopub.status.idle": "2021-10-01T09:43:37.670307Z",
     "shell.execute_reply": "2021-10-01T09:43:37.669627Z",
     "shell.execute_reply.started": "2021-10-01T09:43:37.24759Z"
    }
   },
   "outputs": [],
   "source": [
    "LABEL_COLUMNS = df.columns.tolist()[2:]\n",
    "df[LABEL_COLUMNS].sum().sort_values().plot(kind=\"barh\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-01T09:43:37.671887Z",
     "iopub.status.busy": "2021-10-01T09:43:37.671633Z",
     "iopub.status.idle": "2021-10-01T09:43:38.03772Z",
     "shell.execute_reply": "2021-10-01T09:43:38.036904Z",
     "shell.execute_reply.started": "2021-10-01T09:43:37.671853Z"
    }
   },
   "outputs": [],
   "source": [
    "train_toxic = train_df[train_df[LABEL_COLUMNS].sum(axis=1) > 0]\n",
    "train_clean = train_df[train_df[LABEL_COLUMNS].sum(axis=1) == 0]\n",
    "pd.DataFrame(dict(\n",
    "  toxic=[len(train_toxic)],\n",
    "  clean=[len(train_clean)]\n",
    ")).plot(kind='barh');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-01T09:43:38.039327Z",
     "iopub.status.busy": "2021-10-01T09:43:38.038883Z",
     "iopub.status.idle": "2021-10-01T09:43:38.058336Z",
     "shell.execute_reply": "2021-10-01T09:43:38.057621Z",
     "shell.execute_reply.started": "2021-10-01T09:43:38.039289Z"
    }
   },
   "outputs": [],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-01T09:43:38.060107Z",
     "iopub.status.busy": "2021-10-01T09:43:38.059676Z",
     "iopub.status.idle": "2021-10-01T09:43:39.911179Z",
     "shell.execute_reply": "2021-10-01T09:43:39.910403Z",
     "shell.execute_reply.started": "2021-10-01T09:43:38.06007Z"
    }
   },
   "outputs": [],
   "source": [
    "BERT_MODEL_NAME = 'bert-base-cased'\n",
    "tokenizer = BertTokenizer.from_pretrained(BERT_MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-01T09:43:39.912732Z",
     "iopub.status.busy": "2021-10-01T09:43:39.912467Z",
     "iopub.status.idle": "2021-10-01T09:43:39.920085Z",
     "shell.execute_reply": "2021-10-01T09:43:39.919239Z",
     "shell.execute_reply.started": "2021-10-01T09:43:39.912693Z"
    }
   },
   "outputs": [],
   "source": [
    "LABEL_COLUMNS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-01T09:43:39.921982Z",
     "iopub.status.busy": "2021-10-01T09:43:39.921685Z",
     "iopub.status.idle": "2021-10-01T09:43:39.930846Z",
     "shell.execute_reply": "2021-10-01T09:43:39.929985Z",
     "shell.execute_reply.started": "2021-10-01T09:43:39.921935Z"
    }
   },
   "outputs": [],
   "source": [
    "sample_row = df.iloc[7]\n",
    "sample_comment = sample_row.comment_text\n",
    "sample_labels = sample_row[LABEL_COLUMNS]\n",
    "print(sample_comment)\n",
    "print()\n",
    "print(sample_labels.to_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-01T09:43:39.932373Z",
     "iopub.status.busy": "2021-10-01T09:43:39.932014Z",
     "iopub.status.idle": "2021-10-01T09:43:39.950695Z",
     "shell.execute_reply": "2021-10-01T09:43:39.949875Z",
     "shell.execute_reply.started": "2021-10-01T09:43:39.932339Z"
    }
   },
   "outputs": [],
   "source": [
    "encoding = tokenizer.encode_plus(\n",
    "  sample_comment,\n",
    "  add_special_tokens=True,\n",
    "  max_length=512,\n",
    "  return_token_type_ids=False,\n",
    "  padding=\"max_length\",\n",
    "  return_attention_mask=True,\n",
    "  return_tensors='pt',\n",
    ")\n",
    "encoding.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-01T09:43:39.952409Z",
     "iopub.status.busy": "2021-10-01T09:43:39.952132Z",
     "iopub.status.idle": "2021-10-01T09:43:39.959869Z",
     "shell.execute_reply": "2021-10-01T09:43:39.957583Z",
     "shell.execute_reply.started": "2021-10-01T09:43:39.952377Z"
    }
   },
   "outputs": [],
   "source": [
    "encoding[\"input_ids\"].shape, encoding[\"attention_mask\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-01T09:43:39.961703Z",
     "iopub.status.busy": "2021-10-01T09:43:39.961503Z",
     "iopub.status.idle": "2021-10-01T09:43:39.984724Z",
     "shell.execute_reply": "2021-10-01T09:43:39.984024Z",
     "shell.execute_reply.started": "2021-10-01T09:43:39.961683Z"
    }
   },
   "outputs": [],
   "source": [
    "encoding[\"input_ids\"][0][0:40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-01T09:43:39.989908Z",
     "iopub.status.busy": "2021-10-01T09:43:39.989255Z",
     "iopub.status.idle": "2021-10-01T09:43:39.99702Z",
     "shell.execute_reply": "2021-10-01T09:43:39.99622Z",
     "shell.execute_reply.started": "2021-10-01T09:43:39.989864Z"
    }
   },
   "outputs": [],
   "source": [
    "encoding[\"attention_mask\"][0][0:40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-01T09:43:39.998648Z",
     "iopub.status.busy": "2021-10-01T09:43:39.998199Z",
     "iopub.status.idle": "2021-10-01T09:43:40.006592Z",
     "shell.execute_reply": "2021-10-01T09:43:40.005637Z",
     "shell.execute_reply.started": "2021-10-01T09:43:39.998613Z"
    }
   },
   "outputs": [],
   "source": [
    "encoding[\"input_ids\"].squeeze()[0:40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-01T09:43:40.008464Z",
     "iopub.status.busy": "2021-10-01T09:43:40.008076Z",
     "iopub.status.idle": "2021-10-01T09:43:40.016903Z",
     "shell.execute_reply": "2021-10-01T09:43:40.016068Z",
     "shell.execute_reply.started": "2021-10-01T09:43:40.008428Z"
    }
   },
   "outputs": [],
   "source": [
    "#inverse the tokenization and get back (kinda) the words from the token id\n",
    "\n",
    "print(tokenizer.convert_ids_to_tokens(encoding[\"input_ids\"].squeeze())[:40])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-01T09:43:40.019014Z",
     "iopub.status.busy": "2021-10-01T09:43:40.018491Z",
     "iopub.status.idle": "2021-10-01T09:43:41.07482Z",
     "shell.execute_reply": "2021-10-01T09:43:41.0741Z",
     "shell.execute_reply.started": "2021-10-01T09:43:40.01898Z"
    }
   },
   "outputs": [],
   "source": [
    "# We need to specify the maximum number of tokens when encoding (512 is the maximum we can do)\n",
    "\n",
    "token_counts = []\n",
    "for _, row in train_df.iterrows():\n",
    "  token_count = len(tokenizer.encode(\n",
    "    row[\"comment_text\"],\n",
    "    max_length=512,\n",
    "    truncation=True\n",
    "  ))\n",
    "  token_counts.append(token_count)\n",
    "    \n",
    "sns.histplot(token_counts)\n",
    "plt.xlim([0, 512]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-01T09:43:41.076502Z",
     "iopub.status.busy": "2021-10-01T09:43:41.076242Z",
     "iopub.status.idle": "2021-10-01T09:43:41.08014Z",
     "shell.execute_reply": "2021-10-01T09:43:41.07947Z",
     "shell.execute_reply.started": "2021-10-01T09:43:41.076468Z"
    }
   },
   "outputs": [],
   "source": [
    "# we’ll stick with the limit of 512\n",
    "\n",
    "MAX_TOKEN_COUNT = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-01T09:43:41.081847Z",
     "iopub.status.busy": "2021-10-01T09:43:41.08143Z",
     "iopub.status.idle": "2021-10-01T09:43:41.091489Z",
     "shell.execute_reply": "2021-10-01T09:43:41.090781Z",
     "shell.execute_reply.started": "2021-10-01T09:43:41.081812Z"
    }
   },
   "outputs": [],
   "source": [
    "# We’ll wrap the tokenization process in a PyTorch Dataset, along with converting the labels to tensors:\n",
    "\n",
    "class ToxicCommentsDataset(Dataset):\n",
    "  def __init__(self,data: pd.DataFrame,tokenizer: BertTokenizer,max_token_len: int = 128):\n",
    "    self.tokenizer = tokenizer\n",
    "    self.data = data\n",
    "    self.max_token_len = max_token_len\n",
    "  def __len__(self):\n",
    "    return len(self.data)\n",
    "  def __getitem__(self, index: int):\n",
    "    data_row = self.data.iloc[index]\n",
    "    comment_text = data_row.comment_text\n",
    "    labels = data_row[LABEL_COLUMNS]\n",
    "    encoding = self.tokenizer.encode_plus(\n",
    "      comment_text,\n",
    "      add_special_tokens=True,\n",
    "      max_length=self.max_token_len,\n",
    "      return_token_type_ids=False,\n",
    "      padding=\"max_length\",\n",
    "      truncation=True,\n",
    "      return_attention_mask=True,\n",
    "      return_tensors='pt',\n",
    "    )\n",
    "    return dict(\n",
    "      comment_text=comment_text,\n",
    "      input_ids=encoding[\"input_ids\"].flatten(),\n",
    "      attention_mask=encoding[\"attention_mask\"].flatten(),\n",
    "      labels=torch.FloatTensor(labels)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-01T09:43:41.093015Z",
     "iopub.status.busy": "2021-10-01T09:43:41.092746Z",
     "iopub.status.idle": "2021-10-01T09:43:41.105264Z",
     "shell.execute_reply": "2021-10-01T09:43:41.10425Z",
     "shell.execute_reply.started": "2021-10-01T09:43:41.09298Z"
    }
   },
   "outputs": [],
   "source": [
    "# Let’s have a look at a sample item from the dataset:\n",
    "train_dataset = ToxicCommentsDataset(\n",
    "  train_df,\n",
    "  tokenizer,\n",
    "  max_token_len=MAX_TOKEN_COUNT\n",
    ")\n",
    "sample_item = train_dataset[0]\n",
    "sample_item.keys()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-01T09:43:41.106951Z",
     "iopub.status.busy": "2021-10-01T09:43:41.106688Z",
     "iopub.status.idle": "2021-10-01T09:43:41.115159Z",
     "shell.execute_reply": "2021-10-01T09:43:41.11424Z",
     "shell.execute_reply.started": "2021-10-01T09:43:41.10692Z"
    }
   },
   "outputs": [],
   "source": [
    "sample_item[\"comment_text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-01T09:43:41.116968Z",
     "iopub.status.busy": "2021-10-01T09:43:41.116659Z",
     "iopub.status.idle": "2021-10-01T09:43:41.160812Z",
     "shell.execute_reply": "2021-10-01T09:43:41.160192Z",
     "shell.execute_reply.started": "2021-10-01T09:43:41.116933Z"
    }
   },
   "outputs": [],
   "source": [
    "sample_item[\"labels\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-01T09:43:41.162264Z",
     "iopub.status.busy": "2021-10-01T09:43:41.161931Z",
     "iopub.status.idle": "2021-10-01T09:43:41.168074Z",
     "shell.execute_reply": "2021-10-01T09:43:41.167155Z",
     "shell.execute_reply.started": "2021-10-01T09:43:41.16223Z"
    }
   },
   "outputs": [],
   "source": [
    "sample_item[\"input_ids\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-01T09:43:41.17041Z",
     "iopub.status.busy": "2021-10-01T09:43:41.169557Z",
     "iopub.status.idle": "2021-10-01T09:43:44.914646Z",
     "shell.execute_reply": "2021-10-01T09:43:44.913887Z",
     "shell.execute_reply.started": "2021-10-01T09:43:41.170374Z"
    }
   },
   "outputs": [],
   "source": [
    "# Let’s load the BERT model and pass a sample of batch data through\n",
    "\n",
    "bert_model = BertModel.from_pretrained(BERT_MODEL_NAME, return_dict=True)\n",
    "sample_batch = next(iter(DataLoader(train_dataset, batch_size=8, num_workers=2)))\n",
    "sample_batch[\"input_ids\"].shape, sample_batch[\"attention_mask\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-01T09:43:44.917146Z",
     "iopub.status.busy": "2021-10-01T09:43:44.916223Z",
     "iopub.status.idle": "2021-10-01T09:43:56.029112Z",
     "shell.execute_reply": "2021-10-01T09:43:56.028227Z",
     "shell.execute_reply.started": "2021-10-01T09:43:44.917102Z"
    }
   },
   "outputs": [],
   "source": [
    "output = bert_model(sample_batch[\"input_ids\"], sample_batch[\"attention_mask\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-01T09:43:56.031029Z",
     "iopub.status.busy": "2021-10-01T09:43:56.030749Z",
     "iopub.status.idle": "2021-10-01T09:43:56.035995Z",
     "shell.execute_reply": "2021-10-01T09:43:56.035318Z",
     "shell.execute_reply.started": "2021-10-01T09:43:56.030992Z"
    }
   },
   "outputs": [],
   "source": [
    "output.last_hidden_state.shape, output.pooler_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-01T09:43:56.038151Z",
     "iopub.status.busy": "2021-10-01T09:43:56.037736Z",
     "iopub.status.idle": "2021-10-01T09:43:56.051278Z",
     "shell.execute_reply": "2021-10-01T09:43:56.050411Z",
     "shell.execute_reply.started": "2021-10-01T09:43:56.038117Z"
    }
   },
   "outputs": [],
   "source": [
    "# Note! - The 768 dimension comes from the BERT hidden size\n",
    "bert_model.config.hidden_size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-01T09:43:56.053121Z",
     "iopub.status.busy": "2021-10-01T09:43:56.052831Z",
     "iopub.status.idle": "2021-10-01T09:43:56.063098Z",
     "shell.execute_reply": "2021-10-01T09:43:56.062271Z",
     "shell.execute_reply.started": "2021-10-01T09:43:56.053087Z"
    }
   },
   "outputs": [],
   "source": [
    "# We’ll wrap our custom dataset into a LightningDataModule:\n",
    "# ToxicCommentDataModule - encapsulates all data loading logic and returns the necessary data loaders\n",
    "\n",
    "class ToxicCommentDataModule(pl.LightningDataModule):\n",
    "  def __init__(self, train_df, test_df, tokenizer, batch_size=8, max_token_len=128):\n",
    "    super().__init__()\n",
    "    self.batch_size = batch_size\n",
    "    self.train_df = train_df\n",
    "    self.test_df = test_df\n",
    "    self.tokenizer = tokenizer\n",
    "    self.max_token_len = max_token_len\n",
    "  def setup(self, stage=None):\n",
    "    self.train_dataset = ToxicCommentsDataset(\n",
    "      self.train_df,\n",
    "      self.tokenizer,\n",
    "      self.max_token_len\n",
    "    )\n",
    "    self.test_dataset = ToxicCommentsDataset(\n",
    "      self.test_df,\n",
    "      self.tokenizer,\n",
    "      self.max_token_len\n",
    "    )\n",
    "  def train_dataloader(self):\n",
    "    return DataLoader(\n",
    "      self.train_dataset,\n",
    "      batch_size=self.batch_size,\n",
    "      shuffle=True,\n",
    "      num_workers=2\n",
    "    )\n",
    "  def val_dataloader(self):\n",
    "    return DataLoader(\n",
    "      self.test_dataset,\n",
    "      batch_size=self.batch_size,\n",
    "      num_workers=2\n",
    "    )\n",
    "  def test_dataloader(self):\n",
    "    return DataLoader(\n",
    "      self.test_dataset,\n",
    "      batch_size=self.batch_size,\n",
    "      num_workers=2\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-01T09:43:56.064833Z",
     "iopub.status.busy": "2021-10-01T09:43:56.064352Z",
     "iopub.status.idle": "2021-10-01T09:43:56.074398Z",
     "shell.execute_reply": "2021-10-01T09:43:56.073719Z",
     "shell.execute_reply.started": "2021-10-01T09:43:56.064799Z"
    }
   },
   "outputs": [],
   "source": [
    "# create an instance of our data module\n",
    "\n",
    "N_EPOCHS = 10\n",
    "BATCH_SIZE = 12\n",
    "data_module = ToxicCommentDataModule(\n",
    "  train_df,\n",
    "  val_df,\n",
    "  tokenizer,\n",
    "  batch_size=BATCH_SIZE,\n",
    "  max_token_len=MAX_TOKEN_COUNT\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model\n",
    "**model** will use a pre-trained BertModel and a linear layer to convert the BERT representation to a classification task.\n",
    "We’ll pack everything in a LightningModule:\n",
    "\n",
    "**points of interest** - are the way we configure the optimizers and calculating the area under ROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-01T09:43:56.076147Z",
     "iopub.status.busy": "2021-10-01T09:43:56.075812Z",
     "iopub.status.idle": "2021-10-01T09:43:56.093695Z",
     "shell.execute_reply": "2021-10-01T09:43:56.093022Z",
     "shell.execute_reply.started": "2021-10-01T09:43:56.076115Z"
    }
   },
   "outputs": [],
   "source": [
    "class ToxicCommentTagger(pl.LightningModule):\n",
    "  def __init__(self, n_classes: int, n_training_steps=None, n_warmup_steps=None):\n",
    "    super().__init__()\n",
    "    self.bert = BertModel.from_pretrained(BERT_MODEL_NAME, return_dict=True)\n",
    "    self.classifier = nn.Linear(self.bert.config.hidden_size, n_classes)\n",
    "    self.n_training_steps = n_training_steps\n",
    "    self.n_warmup_steps = n_warmup_steps\n",
    "    self.criterion = nn.BCELoss()\n",
    "  def forward(self, input_ids, attention_mask, labels=None):\n",
    "    output = self.bert(input_ids, attention_mask=attention_mask)\n",
    "    output = self.classifier(output.pooler_output)\n",
    "    output = torch.sigmoid(output)\n",
    "    loss = 0\n",
    "    if labels is not None:\n",
    "        loss = self.criterion(output, labels)\n",
    "    return loss, output\n",
    "  def training_step(self, batch, batch_idx):\n",
    "    input_ids = batch[\"input_ids\"]\n",
    "    attention_mask = batch[\"attention_mask\"]\n",
    "    labels = batch[\"labels\"]\n",
    "    loss, outputs = self(input_ids, attention_mask, labels)\n",
    "    self.log(\"train_loss\", loss, prog_bar=True, logger=True)\n",
    "    return {\"loss\": loss, \"predictions\": outputs, \"labels\": labels}\n",
    "  def validation_step(self, batch, batch_idx):\n",
    "    input_ids = batch[\"input_ids\"]\n",
    "    attention_mask = batch[\"attention_mask\"]\n",
    "    labels = batch[\"labels\"]\n",
    "    loss, outputs = self(input_ids, attention_mask, labels)\n",
    "    self.log(\"val_loss\", loss, prog_bar=True, logger=True)\n",
    "    return loss\n",
    "  def test_step(self, batch, batch_idx):\n",
    "    input_ids = batch[\"input_ids\"]\n",
    "    attention_mask = batch[\"attention_mask\"]\n",
    "    labels = batch[\"labels\"]\n",
    "    loss, outputs = self(input_ids, attention_mask, labels)\n",
    "    self.log(\"test_loss\", loss, prog_bar=True, logger=True)\n",
    "    return loss\n",
    "  def training_epoch_end(self, outputs):\n",
    "    labels = []\n",
    "    predictions = []\n",
    "    for output in outputs:\n",
    "      for out_labels in output[\"labels\"].detach().cpu():\n",
    "        labels.append(out_labels)\n",
    "      for out_predictions in output[\"predictions\"].detach().cpu():\n",
    "        predictions.append(out_predictions)\n",
    "    labels = torch.stack(labels).int()\n",
    "    predictions = torch.stack(predictions)\n",
    "    for i, name in enumerate(LABEL_COLUMNS):\n",
    "      class_roc_auc = auroc(predictions[:, i], labels[:, i])\n",
    "      self.logger.experiment.add_scalar(f\"{name}_roc_auc/Train\", class_roc_auc, self.current_epoch)\n",
    "  def configure_optimizers(self):\n",
    "    optimizer = AdamW(self.parameters(), lr=2e-5)\n",
    "    scheduler = get_linear_schedule_with_warmup(\n",
    "      optimizer,\n",
    "      num_warmup_steps=self.n_warmup_steps,\n",
    "      num_training_steps=self.n_training_steps\n",
    "    )\n",
    "    return dict(\n",
    "      optimizer=optimizer,\n",
    "      lr_scheduler=dict(\n",
    "        scheduler=scheduler,\n",
    "        interval='step'\n",
    "      )\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Optimizer schedule**r -The job of a scheduler is to change the learning rate of the optimizer during training. This might lead to better performance of our model. We’ll use the get_linear_schedule_with_warmup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-01T09:43:56.095509Z",
     "iopub.status.busy": "2021-10-01T09:43:56.095218Z",
     "iopub.status.idle": "2021-10-01T09:43:56.844496Z",
     "shell.execute_reply": "2021-10-01T09:43:56.843756Z",
     "shell.execute_reply.started": "2021-10-01T09:43:56.095476Z"
    }
   },
   "outputs": [],
   "source": [
    "#  simple example to make things clearer\n",
    "\n",
    "dummy_model = nn.Linear(2, 1)\n",
    "optimizer = AdamW(params=dummy_model.parameters(), lr=0.001)\n",
    "warmup_steps = 20\n",
    "total_training_steps = 100\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "  optimizer,\n",
    "  num_warmup_steps=warmup_steps,\n",
    "  num_training_steps=total_training_steps\n",
    ")\n",
    "learning_rate_history = []\n",
    "for step in range(total_training_steps):\n",
    "  optimizer.step()\n",
    "  scheduler.step()\n",
    "  learning_rate_history.append(optimizer.param_groups[0]['lr'])\n",
    "plt.plot(learning_rate_history, label=\"learning rate\")\n",
    "plt.axvline(x=warmup_steps, color=\"red\", linestyle=(0, (5, 10)), label=\"warmup end\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"Step\")\n",
    "plt.ylabel(\"Learning rate\")\n",
    "plt.tight_layout();\n",
    "\n",
    "print('Linear learning rate scheduling over training steps')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use the scheduler, we need to calculate the number of training and warm-up steps. The number of training steps per epoch is equal to number of training examples / batch size. The number of total training steps is training steps per epoch * number of epochs\n",
    "\n",
    "We’ll use a fifth of the training steps for a warm-up:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-01T09:43:56.845705Z",
     "iopub.status.busy": "2021-10-01T09:43:56.845466Z",
     "iopub.status.idle": "2021-10-01T09:43:56.852912Z",
     "shell.execute_reply": "2021-10-01T09:43:56.852196Z",
     "shell.execute_reply.started": "2021-10-01T09:43:56.845672Z"
    }
   },
   "outputs": [],
   "source": [
    "steps_per_epoch=len(train_df) // BATCH_SIZE\n",
    "total_training_steps = steps_per_epoch * N_EPOCHS\n",
    "\n",
    "warmup_steps = total_training_steps // 5\n",
    "warmup_steps, total_training_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-01T09:43:56.854683Z",
     "iopub.status.busy": "2021-10-01T09:43:56.854096Z",
     "iopub.status.idle": "2021-10-01T09:43:59.893128Z",
     "shell.execute_reply": "2021-10-01T09:43:59.892356Z",
     "shell.execute_reply.started": "2021-10-01T09:43:56.854647Z"
    }
   },
   "outputs": [],
   "source": [
    "# create an instance of the model\n",
    "model = ToxicCommentTagger(\n",
    "  n_classes=len(LABEL_COLUMNS),\n",
    "  n_warmup_steps=warmup_steps,\n",
    "  n_training_steps=total_training_steps\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation\n",
    "We’ll use **Binary Cross Entropy** to measure the error for each label. PyTorch has **BCELoss**, which we’re going to combine with a sigmoid function (as we did in the model implementation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-01T09:43:59.894903Z",
     "iopub.status.busy": "2021-10-01T09:43:59.894638Z",
     "iopub.status.idle": "2021-10-01T09:43:59.903893Z",
     "shell.execute_reply": "2021-10-01T09:43:59.903071Z",
     "shell.execute_reply.started": "2021-10-01T09:43:59.89487Z"
    }
   },
   "outputs": [],
   "source": [
    "# example - Loss Calc\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "prediction = torch.FloatTensor([10.95873564, 1.07321467, 1.58524066, 0.03839076, 15.72987556, 1.09513213])\n",
    "\n",
    "labels = torch.FloatTensor([1., 0., 0., 0., 1., 0.])\n",
    "\n",
    "print(torch.sigmoid(prediction))\n",
    "print(criterion(torch.sigmoid(prediction), labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-01T09:43:59.905988Z",
     "iopub.status.busy": "2021-10-01T09:43:59.905549Z",
     "iopub.status.idle": "2021-10-01T09:44:11.595131Z",
     "shell.execute_reply": "2021-10-01T09:44:11.593834Z",
     "shell.execute_reply.started": "2021-10-01T09:43:59.905952Z"
    }
   },
   "outputs": [],
   "source": [
    "# calculate the loss of the prediction\n",
    "\n",
    "_, predictions = model(sample_batch[\"input_ids\"], sample_batch[\"attention_mask\"])\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-01T09:44:11.59684Z",
     "iopub.status.busy": "2021-10-01T09:44:11.596324Z",
     "iopub.status.idle": "2021-10-01T09:44:11.603914Z",
     "shell.execute_reply": "2021-10-01T09:44:11.603142Z",
     "shell.execute_reply.started": "2021-10-01T09:44:11.596803Z"
    }
   },
   "outputs": [],
   "source": [
    "criterion(predictions, sample_batch[\"labels\"])"
   ]
  },
  {
   "attachments": {
    "2bd8a67f-1611-4932-8b67-af1438a334c8.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ROC Curve\n",
    "The area under the Receiver operating characteristic (ROC) for each tag. ROC is created by plotting the True Positive Rate (TPR) vs False Positive Rate (FPR)\n",
    "\n",
    "![image.png](attachment:2bd8a67f-1611-4932-8b67-af1438a334c8.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-01T09:44:11.605419Z",
     "iopub.status.busy": "2021-10-01T09:44:11.605079Z",
     "iopub.status.idle": "2021-10-01T09:44:11.962839Z",
     "shell.execute_reply": "2021-10-01T09:44:11.962141Z",
     "shell.execute_reply.started": "2021-10-01T09:44:11.605385Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "fpr = [0.        , 0.        , 0.        , 0.02857143, 0.02857143,\n",
    "       0.11428571, 0.11428571, 0.2       , 0.4       , 1.        ]\n",
    "tpr = [0.        , 0.01265823, 0.67202532, 0.76202532, 0.91468354,\n",
    "       0.97468354, 0.98734177, 0.98734177, 1.        , 1.        ]\n",
    "_, ax = plt.subplots()\n",
    "ax.plot(fpr, tpr, label=\"ROC\")\n",
    "ax.plot([0.05, 0.95], [0.05, 0.95], transform=ax.transAxes, label=\"Random classifier\", color=\"red\")\n",
    "ax.legend(loc=4)\n",
    "ax.set_xlabel(\"False positive rate\")\n",
    "ax.set_ylabel(\"True positive rate\")\n",
    "ax.set_title(\"Example ROC curve\")\n",
    "plt.show();\n",
    "\n",
    "print('Example ROC value of a trained classifier vs random classifier')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training\n",
    "we'll use at least 3 components - **Checkpointing** that saves the best model (based on validation loss):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-01T09:44:11.964966Z",
     "iopub.status.busy": "2021-10-01T09:44:11.964191Z",
     "iopub.status.idle": "2021-10-01T09:44:11.971709Z",
     "shell.execute_reply": "2021-10-01T09:44:11.970964Z",
     "shell.execute_reply.started": "2021-10-01T09:44:11.964925Z"
    }
   },
   "outputs": [],
   "source": [
    "checkpoint_callback = ModelCheckpoint(\n",
    "    dirpath=\"checkpoints\",\n",
    "    filename=\"best-checkpoint\",\n",
    "    save_top_k=1,\n",
    "    verbose=True,\n",
    "    monitor=\"val_loss\",\n",
    "    mode=\"min\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-01T09:44:11.973687Z",
     "iopub.status.busy": "2021-10-01T09:44:11.973416Z",
     "iopub.status.idle": "2021-10-01T09:44:11.979594Z",
     "shell.execute_reply": "2021-10-01T09:44:11.97875Z",
     "shell.execute_reply.started": "2021-10-01T09:44:11.973652Z"
    }
   },
   "outputs": [],
   "source": [
    "# Log the progress in TensorBoard:\n",
    "\n",
    "logger = TensorBoardLogger(\"lightning_logs\", name=\"toxic-comments\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-01T09:44:11.981319Z",
     "iopub.status.busy": "2021-10-01T09:44:11.981033Z",
     "iopub.status.idle": "2021-10-01T09:44:11.987589Z",
     "shell.execute_reply": "2021-10-01T09:44:11.986814Z",
     "shell.execute_reply.started": "2021-10-01T09:44:11.981287Z"
    }
   },
   "outputs": [],
   "source": [
    "# And early stopping triggers when the loss hasn’t improved for the last 2 epochs \n",
    "#(you might want to remove/reconsider this when training on real-world projects):\n",
    "early_stopping_callback = EarlyStopping(monitor='val_loss', patience=2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-01T09:44:11.990029Z",
     "iopub.status.busy": "2021-10-01T09:44:11.989817Z",
     "iopub.status.idle": "2021-10-01T09:44:12.107099Z",
     "shell.execute_reply": "2021-10-01T09:44:12.106275Z",
     "shell.execute_reply.started": "2021-10-01T09:44:11.990007Z"
    }
   },
   "outputs": [],
   "source": [
    "# start the training process:\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    logger=logger,\n",
    "    callbacks=[checkpoint_callback, early_stopping_callback],\n",
    "    max_epochs=1,#N_EPOCHS,\n",
    "    gpus=1,\n",
    "    progress_bar_refresh_rate=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-01T09:44:12.109154Z",
     "iopub.status.busy": "2021-10-01T09:44:12.108797Z"
    }
   },
   "outputs": [],
   "source": [
    "trainer.fit(model, data_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('finish')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
